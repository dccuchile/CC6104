str(dd.trim)
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[ complete.cases(d$rgdppc_2000) , ]
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
str(dd.trim)
m.reg1 <- ulam(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
) ,
data=dd.trim )
precis(m.reg1)
show(m.reg1 )
str(dd.trim)
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[ complete.cases(d$rgdppc_2000) , ]
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
str(dd.trim)
m.reg1 <- ulam(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
) ,
data=dd.trim )
precis(m.reg1)
show(m.reg1 )
stancode(m.reg1)
View(dd.trim)
summary(dd.trim)
View(rugged)
View(dd.trim)
View(dd)
complete.cases
?complete.cases
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
#remove rows with missing values
dd <- d[ complete.cases(d$rgdppc_2000) , ]
# discard columns we are not going to use
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
summary(dd.trim)
m.reg1 <- ulam(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
) ,
data=dd.trim )
precis(m.reg1)
show(m.reg1 )
pairs( m.reg1)
traceplot( m.reg1 )
trankplot( m.reg1 )
model<-alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
)
m.reg1 <- ulam(model ,data=dd.trim )
b.reg3 <- quap (model, data=dd.trim)
precis(m.reg3)
b.reg3 <- quap (model, data=dd.trim)
precis(b.reg3)
?rugged
data(rugged)
View(rugged)
model
model[[7]]
sigma ~ dcauchy(0,2)
sigma ~ dcauchy(0,2)
a= sigma ~ dcauchy(0,2)
a
class(a)
model<-alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ duniform(0,50)
)
b.reg3 <- quap (model, data=dd.trim)
precis(b.reg3)
model<-alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dunif(0,50)
)
b.reg3 <- quap (model, data=dd.trim)
precis(b.reg3)
model<-alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dunif(0,50)
)
b.reg3 <- quap (model, data=dd.trim)
precis(b.reg3)
model<-alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dunif(0,50)
)
b.reg3 <- quap (model, data=dd.trim)
precis(b.reg3)
num_days <- 1e5
positions <- rep(0,num_days)
current <- 10
for ( i in 1:num_days ) {
# record current position
positions[i] <- current
# flip coin to generate proposal
proposal <- current + sample( c(-1,1) , size=1 )
# now make sure he loops around the archipelago
if ( proposal < 1 ) proposal <- 10
if ( proposal > 10 ) proposal <- 1
# move?
prob_move <- min(proposal/current,1)
decision <- rbinom(1,1,prob_move)
current <- ifelse( decision == 1 , proposal , current )
}
library(rethinking)
simplehist(positions,xlab="island",ylab="number of days")
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
#remove rows with missing values
dd <- d[ complete.cases(d$rgdppc_2000) , ]
# discard columns we are not going to use
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
#dd.trim$cont_africa<-as.factor(dd.trim$cont_africa)
summary(dd.trim)
cor(dd.trim$rugged,dd.trim$log_gdp)
dd.A<-dd.trim[dd.trim$cont_africa==1,]
cor(dd.A$rugged,dd.A$log_gdp)
dd.NA<-dd.trim[dd.trim$cont_africa==0,]
cor(dd.NA$rugged,dd.NA$log_gdp)
model<-alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- b0 + b1*rugged + b2*cont_africa + b3*rugged*cont_africa ,
b0 ~ dnorm(0,100),
b1 ~ dnorm(0,10),
b2 ~ dnorm(0,10),
b3 ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
)
b.reg3<-quap(model,data=dd.trim)
precis(b.reg3)
b.reg3<-quap(model,data=dd.trim)
precis(b.reg3)
m.reg1 <- ulam(model ,data=dd.trim, chains=4, cores=4 )
precis(m.reg1)
show(m.reg1)
pairs( m.reg1)
stancode(m.reg1)
traceplot( m.reg1 )
m.reg1 <- ulam(model ,data=dd.trim)
cor(dd.trim$rugged,dd.trim$log_gdp)
dd.A<-dd.trim[dd.trim$cont_africa==1,]
cor(dd.A$rugged,dd.A$log_gdp)
dd.NA<-dd.trim[dd.trim$cont_africa==0,]
cor(dd.NA$rugged,dd.NA$log_gdp)
b.reg3<-quap(model,data=dd.trim)
b.reg3<-quap(model,data=dd.trim)
precis(b.reg3)
precis(b.reg3,prob=0.95 )
precis(m.reg1, prob=0.95 )
m.reg2 <- ulam(model ,data=dd.trim, chains=4, cores=4,iter=2000)
m.reg2 <- ulam(model ,data=dd.trim, iter=3000,
warmup =1000, chains=4, cores=4)
pairs( m.reg1)
show(m.reg1)
post <- extract.samples( m.reg1 )
str(post)
show(m.reg1)
traceplot( m.reg1 )
plot(m.reg1)
plot(m.reg1)
plot(m.reg1)
traceplot( m.reg1 )
show(m.reg2)
show(m.reg1)
show(m.reg1)
stancode(m.reg1)
show(m.reg2)
post <- extract.samples( m.reg1 )
str(post)
post <- extract.samples( m.reg1, n= 1e4 )
str(post)
pairs( m.reg1)
traceplot( m.reg1 )
library(rethinking)
data(Howell1)
wd()
getwd()
cd "workspace/CC6104/scripts/"
cd("workspace/CC6104/scripts/")
setwd("workspace/CC6104/scripts/")
ls
ls()
getwd()
write.csv(Howell1,file = "howell1.csv",row.names = F)
d <- read.csv("howell1.csv")
View(d)
cor(d)
# discard non-adults
d2 <- d[ d$age >= 18 , ]
cor(d2)
#Para ajustar el modelo lineal
reg1<-lm(height~weight,d2)
reg1
reg1$coefficients
reg1.coef<-reg1$coefficients
reg1.coef
summary(reg1)
sum.reg1<-summary(reg1)
sum.reg1$r.squared
SSE<-sum(reg1$residuals^2)
SST<-sum((d2$height-mean(d2$height))^2)
SSM<-sum((reg1$fitted.values-mean(d2$height))^2)
SSM/SST
1-SSE/SST
1-var(reg1$residuals)/var(d2$height)
cor(d2$height,reg1$fitted.values)^2
d <- read.csv("howell1.csv")
install.packages("gdata")
my.sum<-function(a=2,b=1){
return(a+b);
}
my.sum(3,4)
my.sum()
class(my.sum)
a.sum<-sum(ages)
a.length<-length(ages)
ages<-c(21,33,12,34,23,70,90,80,7,29,14,2,
88,11,55,24,13,11,56,28,33)
a.sum<-sum(ages)
a.length<-length(ages)
a.sum<-sum(ages)
a.length<-length(ages)
a.sum
a.length
a.mean<-sum(ages)/length(ages)
a.mean
a.var<-sum((ages-media)^2)/(length(ages)-1)
a.var
a.mean<-sum(ages)/length(ages)
a.mean
a.var<-sum((ages-a.mean)^2)/(length(ages)-1)
a.var
data(iris)
#Para ver las promediedades estadisticas básicas hacemos summary
summary(iris)
#Para ver los atributos del data.frame
names(iris)
dim(iris)
#Para pasar todas las variables del data.frame al ambiente
attach(iris)
#frecuencias
table(iris$Species)
vec<-c(1,1,1,0,0,3,3,3,3,2)
table(vec)
table(vec)/length(vec)  # Frecuencia porcentual
# La moda
my_mode<-function(var){
frec.var<-table(var)
value<-which(frec.var==max(frec.var))# Elements with  the maximum value
as.numeric(names(value))
}
my_mode(vec)
my_mode(iris$Sepal.Length)
#Estadisticos básicos
mean(Sepal.Length)
median(Sepal.Length)
#media truncada define el porcentaje de elementos extremos que no considera
mean(Sepal.Length, trim=0.1)
# Creamos un vector de tamaño 10, con media 20 y sd 10
vec<-rnorm(10,20,10)
mean(vec)
vec.noise<-c(vec,rnorm(1,300,100))
mean(vec.noise)
mean(vec,trim=0.1)
mean(vec.noise,trim=0.1)
median(vec)
median(vec.noise)
# Todos los percentiles
quantile(Sepal.Length,seq(0,1,0.01))
quantile(Sepal.Length,seq(0,1,0.25))
tapply(iris$Petal.Length,iris$Species,summary)
tapply(iris$Petal.Width,iris$Species,summary)
tapply(iris$Sepal.Length,iris$Species,summary)
tapply(iris$Sepal.Width,iris$Species,summary)
summary(iris)
#frecuencia
table(iris$Species)
# Dispercion
range(Sepal.Length)
max(Sepal.Length)-min(Sepal.Length)
sd(Sepal.Length)
sepal.var<-var(Sepal.Length)
#Es equivalente a computarlo como
myvar<-sum((Sepal.Length-mean(Sepal.Length))^2)/(length(Sepal.Length-1))
var(Sepal.Length)
sd(Sepal.Length)
aad<-function(x,fun=median){
mean(abs(x-fun(x)))
}
aad(Sepal.Length)
aad(Sepal.Length,mean)
mad(Sepal.Length)
median(abs(Sepal.Length-median(Sepal.Length)))
mad(Sepal.Length,constant=1)
mad(Sepal.Length,center=mean(Sepal.Length),1)
IQR(Sepal.Length)
?quantile
?IQR
###
cov(Sepal.Length,Sepal.Width)
cov(iris[,1:4])
cor(iris[,1:4])
# Exploración de datos y Visualización
# basado en el capítulo 3 del libro Introduction to Data Mining
# Autor: Felipe Bravo-Marquez
data(iris)
#Para ver las promediedades estadisticas básicas hacemos summary
summary(iris)
#Para ver los atributos del data.frame
names(iris)
dim(iris)
#Para pasar todas las variables del data.frame al ambiente
attach(iris)
#frecuencias
table(iris$Species)
vec<-c(1,1,1,0,0,3,3,3,3,2)
table(vec)
table(vec)/length(vec)  # Frecuencia porcentual
# La moda
my_mode<-function(var){
frec.var<-table(var)
value<-which(frec.var==max(frec.var))# Elements with  the maximum value
as.numeric(names(value))
}
my_mode(vec)
my_mode(iris$Sepal.Length)
#Estadisticos básicos
mean(Sepal.Length)
median(Sepal.Length)
#media truncada define el porcentaje de elementos extremos que no considera
mean(Sepal.Length, trim=0.1)
# Creamos un vector de tamaño 10, con media 20 y sd 10
vec<-rnorm(10,20,10)
mean(vec)
vec.noise<-c(vec,rnorm(1,300,100))
mean(vec.noise)
mean(vec,trim=0.1)
mean(vec.noise,trim=0.1)
median(vec)
median(vec.noise)
# Todos los percentiles
quantile(Sepal.Length,seq(0,1,0.01))
quantile(Sepal.Length,seq(0,1,0.25))
tapply(iris$Petal.Length,iris$Species,summary)
tapply(iris$Petal.Width,iris$Species,summary)
tapply(iris$Sepal.Length,iris$Species,summary)
tapply(iris$Sepal.Width,iris$Species,summary)
summary(iris)
#frecuencia
table(iris$Species)
# Dispercion
range(Sepal.Length)
max(Sepal.Length)-min(Sepal.Length)
sd(Sepal.Length)
sepal.var<-var(Sepal.Length)
#Es equivalente a computarlo como
myvar<-sum((Sepal.Length-mean(Sepal.Length))^2)/(length(Sepal.Length-1))
var(Sepal.Length)
sd(Sepal.Length)
aad<-function(x,fun=median){
mean(abs(x-fun(x)))
}
aad(Sepal.Length)
aad(Sepal.Length,mean)
mad(Sepal.Length)
median(abs(Sepal.Length-median(Sepal.Length)))
mad(Sepal.Length,constant=1)
mad(Sepal.Length,center=mean(Sepal.Length),1)
IQR(Sepal.Length)
?quantile
?IQR
###
cov(Sepal.Length,Sepal.Width)
cov(iris[,1:4])
cor(iris[,1:4])
# Tablas de Contingencia
gender<-c("Male", "Female", "Male", "Female", "Female", "Male")
studies<-c("college","postgraduate","high school",
"postgraduate","high school","college")
table(gender,studies)
weather<-read.table("weather.nominal.csv",header=T,sep=",")
table(weather$outlook,weather$play)
table(weather$temperature,weather$play)
library(modeest)
#Visualización
png("imagen.png")
plot(1:10)
dev.off()
plot(rnorm(15,10,5),col="red",type="p",pch=1)
lines(rnorm(15,10,5),col="blue",type="p",pch=1)
lines(rnorm(15,10,5),col="green",type="b",pch=2)
title(main="My Plot")
legend('topright', c("lines","dots","both") ,
lty=1:3, col=c("red", "blue","green"), bty='n', cex=.75)
## Histogramas
hist(Sepal.Length)
lines(density(Sepal.Length))
hist(Sepal.Length,nclass=length(Sepal.Length))
## con ggplot2
library(ggplot2)
# Basic histogram
ggplot(iris, aes(x=Sepal.Length)) + geom_histogram(bins = 10, color="black", fill="white")
plot(density(iris$Sepal.Length),main="Density of Sepal.Length")
plot(density(iris$Sepal.Length),col="red",main="Densidad")
pie(table(iris$Species))
boxplot(Sepal.Length,main="Boxplot Sepal.Length")
boxplot(Sepal.Length~Species,ylab="Sepal.Length")
boxplot(x=iris[,1:4],main="Boxplots Iris")
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
geom_boxplot()
plot(Sepal.Width~Sepal.Length, col=Species)
plot(Sepal.Length, Sepal.Width,col=Species,
pch=as.numeric(Species))
legend('topright', levels(Species) ,
lty=1, col=1:3, bty='n', cex=.75)
ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) + geom_point(size=3,shape=4)
plot(iris)
pairs(iris)
pairs(iris[,1:4],pch=as.numeric(iris$Species),col=iris$Species)
plot(iris$Sepal.Length,col=as.numeric(iris$Species))
plot(Sepal.Length, Sepal.Width, col=Species, pch=as.numeric(Species))
legend('topright', levels(Species) ,
lty=1, col=c('red', 'blue', 'green'), bty='n', cex=.75)
ggpairs(iris[,1:4])
dev.off()
library(scatterplot3d)
scatterplot3d(iris$Petal.Width, iris$Sepal.Length, iris$Sepal.Width, color=as.numeric(iris$Species))
library(MASS)
parcoord(iris[1:4], col=iris$Species,var.label=T)
iris_sample1<-iris[sample(1:dim(iris)[1],size=6,replace=F),]
rownames(iris_sample1)<-paste(as.character(iris_sample1$Species),1:6)
stars(iris_sample1[1:4])
library("aplpack")
iris_sample<-iris[sample(1:dim(iris)[1],size=16,replace=F),]
faces(iris_sample[1:4],face.type=1,labels=iris_sample$Species)
library(gplots)
library(ggplot2)
qplot(Sepal.Length,data=iris,geom ="histogram",binwidth=0.1)
qplot(Sepal.Length,data=iris,geom ="density")
cor(iris[,1:4])
install.packages("GGally")
install.packages("GGally")
install.packages("GGally")
install.packages("GGally")
install.packages("GGally")
ggcor
# we recommend running this is a fresh R session or restarting your current session
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
cmdstanr::install_cmdstan()
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty", "shape"))
cmdstanr::install_cmdstan()
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
